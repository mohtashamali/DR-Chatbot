🧑‍⚕️ DR-LLM 

Dr LLm is a virtual doctor assistant that uses **Groq-hosted LLMs** to understand **voice and image inputs** and provide **intelligent, medically relevant responses**. The project combines voice recognition, image processing, and large language model capabilities to simulate human-like interactions with a virtual doctor.

## 🔍 Features

- 🎙️ **Voice Input**: Speak to the assistant naturally using a microphone.
- 🖼️ **Image Input**: Upload medical images (e.g., X-rays, reports).
- 🧠 **Groq LLM Integration**: Leverages ultra-fast inference for real-time answers.
- 🩺 **Doctor-like Responses**: Generates context-aware, medical-grade explanations.
- 🌐 **Gradio Frontend**: Interactive web UI for testing and demonstration.


## 🚀 Tech Stack

| Component             | Technology                     |
|----------------------|--------------------------------|
| 🧠 LLM Backend        | Groq-hosted LLM (e.g., LLaMA, Mistral) |
| 🎙️ Speech-to-Text     | `speech_recognition`, Google STT |
| 🖼️ Image Input         | Gradio File/Image Upload       |
| 🗣️ Text-to-Speech      | `gTTS` (Google Text-to-Speech) |
| 🌐 Frontend UI         | `Gradio`                       |
| 🐍 Language            | Python                         |

---

->Installation
* better if used **virtual environment**
and dowloand req.txt
# # To Run the program 
-> inside the virtual environment
python doctor.py 


