ðŸ§‘â€âš•ï¸ DR-LLM 

Dr LLm is a virtual doctor assistant that uses **Groq-hosted LLMs** to understand **voice and image inputs** and provide **intelligent, medically relevant responses**. The project combines voice recognition, image processing, and large language model capabilities to simulate human-like interactions with a virtual doctor.

## ðŸ” Features

- ðŸŽ™ï¸ **Voice Input**: Speak to the assistant naturally using a microphone.
- ðŸ–¼ï¸ **Image Input**: Upload medical images (e.g., X-rays, reports).
- ðŸ§  **Groq LLM Integration**: Leverages ultra-fast inference for real-time answers.
- ðŸ©º **Doctor-like Responses**: Generates context-aware, medical-grade explanations.
- ðŸŒ **Gradio Frontend**: Interactive web UI for testing and demonstration.


## ðŸš€ Tech Stack

| Component             | Technology                     |
|----------------------|--------------------------------|
| ðŸ§  LLM Backend        | Groq-hosted LLM (e.g., LLaMA, Mistral) |
| ðŸŽ™ï¸ Speech-to-Text     | `speech_recognition`, Google STT |
| ðŸ–¼ï¸ Image Input         | Gradio File/Image Upload       |
| ðŸ—£ï¸ Text-to-Speech      | `gTTS` (Google Text-to-Speech) |
| ðŸŒ Frontend UI         | `Gradio`                       |
| ðŸ Language            | Python                         |

---

->Installation
* better if used **virtual environment**
and dowloand req.txt
# # To Run the program 
-> inside the virtual environment
python doctor.py 


